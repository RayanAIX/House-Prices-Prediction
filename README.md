# ğŸ¡ House Prices Prediction (Advanced Regression)

---

## ğŸ“˜ Project Overview

This project aims to **predict the final selling price of residential homes** using advanced machine learning regression techniques.  
Itâ€™s part of the **Kaggle â€œHouse Prices - Advanced Regression Techniquesâ€ competition**, where the goal is to build a model that accurately estimates prices based on multiple house attributes.

This project demonstrates **data preprocessing, feature engineering, model stacking, and ensemble learning** to achieve a **high Kaggle score**.

---

## ğŸš€ Key Features

| Feature | Description |
|----------|--------------|
| ğŸ“Š **Data Preprocessing** | Handled missing values, outliers, and categorical encoding |
| ğŸ§© **Feature Engineering** | Created new meaningful features (e.g., TotalSF, Age, Quality Score) |
| ğŸ”¢ **Advanced Models** | Used StackingRegressor combining XGBoost, LightGBM, and CatBoost |
| âš™ï¸ **Hyperparameter Optimization** | Fine-tuned using GridSearchCV and cross-validation |
| ğŸ“ˆ **Evaluation Metric** | Root Mean Squared Log Error (RMSLE) |
| ğŸ… **Kaggle Score** | Achieved **0.12668** (Top-performing regression model) |

---

## ğŸ§  Machine Learning Workflow

1. **Data Exploration & Visualization**  
   - Analyzed key correlations with `SalePrice`  
   - Visualized distributions and outliers using `matplotlib` & `seaborn`

2. **Data Cleaning**  
   - Imputed missing numeric & categorical data  
   - Removed unnecessary or noisy columns

3. **Feature Engineering**  
   - Combined related features (e.g., `TotalSF = TotalBsmtSF + 1stFlrSF + 2ndFlrSF`)  
   - Applied log transformations to reduce skewness

4. **Encoding & Scaling**  
   - Used Label Encoding and One-Hot Encoding for categorical variables  
   - Scaled numerical features using `StandardScaler`

5. **Modeling & Optimization**  
   - Implemented ensemble of models:
     - **XGBoost Regressor**
     - **LightGBM Regressor**
     - **CatBoost Regressor**
   - Combined them using **StackingRegressor** for final predictions  
   - Used **cross-validation (CV=10)** to ensure robust performance

6. **Submission**  
   - Generated final predictions as `house_prices_highscore.csv`  
   - Submitted to Kaggle achieving a public score of **0.12668**

---

## ğŸ“‚ Dataset Description

| File | Description |
|------|--------------|
| `train.csv` | Training dataset with features and target (`SalePrice`) |
| `test.csv` | Test dataset used for generating predictions |
| `data_description.txt` | Details and explanation of all 79 variables |
| `sample_submission.csv` | Sample submission format for Kaggle |
| `house_prices_highscore.csv` | Final submission file with predictions |

---

## ğŸ§¾ Technologies Used

| Category | Libraries/Tools |
|-----------|-----------------|
| **Programming Language** | Python |
| **Data Analysis** | Pandas, NumPy |
| **Visualization** | Matplotlib, Seaborn |
| **Machine Learning** | Scikit-Learn, XGBoost, LightGBM, CatBoost |
| **Environment** | Google Colab |
| **Platform** | Kaggle |

---

## ğŸ“Š Results Summary

| Model | RMSLE Score |
|--------|--------------|
| Linear Regression | 0.17894 |
| Random Forest | 0.14732 |
| XGBoost | 0.13584 |
| LightGBM | 0.13067 |
| CatBoost | 0.12823 |
| **Stacked Ensemble (Final)** | ğŸ¯ **0.12668** |

---

## ğŸ‘¨â€ğŸ’» Author

**Muhammad Rayan Shahid**  
AI Engineer | ML Researcher | Creator of ByteBrilliance AI  

---

## ğŸŒ Connect With Me

[![GitHub](https://img.shields.io/badge/GitHub-ByteBrillianceAI-black?style=for-the-badge&logo=github)](https://github.com/ByteBrillianceAI)  
[![LinkedIn](https://img.shields.io/badge/LinkedIn-Muhammad_Rayan_Shahid-blue?style=for-the-badge&logo=linkedin)](https://linkedin.com/in/muhammad-rayan-shahid)  
[![Kaggle](https://img.shields.io/badge/Kaggle-RayanShahid-blue?style=for-the-badge&logo=kaggle)](https://kaggle.com/rayanshahid)  
[![Hugging Face](https://img.shields.io/badge/HuggingFace-ByteBrilliance-yellow?style=for-the-badge&logo=huggingface)](https://huggingface.co/ByteBrilliance)  
[![YouTube](https://img.shields.io/badge/YouTube-ByteBrilliance_AI-red?style=for-the-badge&logo=youtube)](https://youtube.com/@ByteBrillianceAI)

---

## ğŸ Future Improvements

- Try **neural network regression models (Keras/TensorFlow)**
- Apply **feature selection using SHAP values**
- Explore **stacking with more advanced base models**
- Implement **automated hyperparameter optimization (Optuna/BayesSearchCV)**

---

## ğŸ“¦ Repository Structure

House-Prices-Prediction/
â”‚
â”œâ”€â”€ train.csv
â”œâ”€â”€ test.csv
â”œâ”€â”€ data_description.txt
â”œâ”€â”€ sample_submission.csv
â”œâ”€â”€ house_prices_highscore.csv
â”œâ”€â”€ house_prices.ipynb
â”œâ”€â”€ README.md
â””â”€â”€ screenshots/
â”œâ”€â”€ data_exploration.png
â”œâ”€â”€ heatmap.png
â”œâ”€â”€ feature_engineering.png
â”œâ”€â”€ model_training.png
â””â”€â”€ submission.png

yaml
Copy code

---

## ğŸ† Kaggle Competition

**Competition:** [House Prices - Advanced Regression Techniques](https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques)  
**Final Score:** ğŸ¯ **0.12668**

---

â­ *If you like this project, donâ€™t forget to star the repository on GitHub!* â­

---
